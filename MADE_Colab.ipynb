{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MADE_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewzKdXcQGnDM",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekA7YT3iFT8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn \n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo0EqlJiGqDH",
        "colab_type": "text"
      },
      "source": [
        "## Data processing / import (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7q84VdFGBtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_set = datasets.MNIST(root='../mnist_data', train=True,  download=True)\n",
        "test_set = datasets.MNIST(root='../mnist_data', train=False, download=True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3yj10FgGG5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((20,20))])\n",
        "\n",
        "class custom_mnist(Dataset):\n",
        "    def __init__(self, input_data):\n",
        "        super().__init__()\n",
        "        self.data = input_data\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(np.array(transform(self.data[idx][0])) > 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Q3M-5JGIzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = custom_mnist(train_set)\n",
        "mnist_test = custom_mnist(test_set)\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=128)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JEthSr3GwEJ",
        "colab_type": "text"
      },
      "source": [
        "## Original Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0G0O9LrGKq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, axarr = plt.subplots(10,10)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        axarr[i,j].imshow(mnist_train[10*i + j])\n",
        "        axarr[i,j].axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02IVt6BBGzgE",
        "colab_type": "text"
      },
      "source": [
        "## MADE Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-zTUdaUGMNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MaskedLayer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super().__init__(in_features, out_features, bias)\n",
        "        self.register_buffer('mask', torch.ones(out_features, in_features))\n",
        "\n",
        "    def set_mask(self, mask):\n",
        "        self.mask.data.copy_(mask.T)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return F.linear(x, self.weight*self.mask, self.bias)\n",
        "\n",
        "\n",
        "# d - number of unique values any pixel can take - (0-255 --> 256) / (0-1 --> 2)\n",
        "# if d = 2, passing it as 1 should also work\n",
        "\n",
        "class MADE(nn.Module):\n",
        "    def __init__(self, input_shape, d,  hidden_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_features = input_shape*d\n",
        "        self.out_features = input_shape*d\n",
        "\n",
        "        \n",
        "        layers = [self.in_features] + hidden_layers + [self.out_features]\n",
        "\n",
        "        self.net = []\n",
        "        self.masks = []\n",
        "        self.m = []\n",
        "        \n",
        "        h1 = layers[:-1]\n",
        "        h2 = layers[1:]\n",
        "\n",
        "        for idx,(i1,i2) in enumerate(zip(h1,h2)):\n",
        "            self.net.append(MaskedLayer(i1,i2))\n",
        "            self.net.append(nn.ReLU())\n",
        "\n",
        "            self.masks.append(torch.zeros(i1,i2))\n",
        "            if (idx == 0):\n",
        "                self.m.append(torch.cat(d*[torch.arange(input_shape)]))\n",
        "                continue\n",
        "\n",
        "            self.m.append(torch.arange(i1))\n",
        "\n",
        "        self.m.append(torch.cat(d*[torch.arange(input_shape)]))\n",
        "\n",
        "        for i in range(0,len(self.m)-2):\n",
        "            mask = (self.m[i][:,None] <= self.m[i+1][None, :]).int()\n",
        "            self.net[2*i].set_mask(mask) \n",
        "\n",
        "        mask = (self.m[-2][:,None] < self.m[-1][None, :]).int()\n",
        "        self.net[-2].set_mask(mask)\n",
        "\n",
        "        self.net.pop()\n",
        "\n",
        "        self.net = nn.ModuleList(self.net)\n",
        "\n",
        "\n",
        "\n",
        "                    \n",
        "    def forward(self,x):\n",
        "        return nn.Sequential(*self.net)(x)\n",
        "        \n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEPrTYniG5GI",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaJDoCfYGXmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "made = MADE(400,1,[400,400]).to(device)\n",
        "optimizer = Adam(made.parameters(), lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "num_epochs = 10\n",
        "train_loss_hist = []\n",
        "valid_loss_hist = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for idx, train_data in tqdm(enumerate(train_loader)):\n",
        "        data = train_data.to(device)\n",
        "        b,_,_ = train_data.shape\n",
        "\n",
        "        data = data.view(b,-1)\n",
        "\n",
        "        pred = made(data)\n",
        "\n",
        "        loss = criterion(pred, data)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_hist.append(loss)\n",
        "\n",
        "    valid_loss = 0\n",
        "    for idx, valid_data in tqdm(enumerate(test_loader)):\n",
        "        data = valid_data.to(device)\n",
        "        b,_,_ = valid_data.shape\n",
        "\n",
        "        data = data.view(b,-1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = made(data)\n",
        "\n",
        "        loss = criterion(pred, data)\n",
        "        valid_loss += loss\n",
        "\n",
        "    valid_loss_hist.append(valid_loss/idx)\n",
        "\n",
        "plt.plot(train_loss_hist)\n",
        "plt.show()\n",
        "plt.plot(valid_loss_hist)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cwSedtTG8og",
        "colab_type": "text"
      },
      "source": [
        "## Sampling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmgD5IfAHBfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model, num_samples, num_input):\n",
        "    out = torch.zeros(num_samples,num_input)\n",
        "\n",
        "    for i in range(num_input):\n",
        "        with torch.no_grad():\n",
        "            logits = made(out.to(device))\n",
        "        samples = torch.bernoulli(torch.sigmoid(logits))\n",
        "\n",
        "        out[:, i] = samples[:, i]\n",
        "\n",
        "    return out.reshape(num_samples, 20,20).detach()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTihmh_FHEZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = sample(made, 100, 400)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaidrpvXHI7m",
        "colab_type": "text"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXg7dyL6HQi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, axarr = plt.subplots(10,10)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        axarr[i,j].imshow(out[10*i + j])\n",
        "        axarr[i,j].axis('off')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF04n2RvHRH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}